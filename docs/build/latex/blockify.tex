%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{blockify}
\date{Sep 13, 2019}
\release{0.1.0}
\author{Arnav Moudgil}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{Introduction}
\label{\detokenize{pages/intro:introduction}}\label{\detokenize{pages/intro::doc}}
blockify is a genomic peak caller for one-dimensional data (e.g. CCF).


\chapter{Command: segment}
\label{\detokenize{pages/segment:command-segment}}\label{\detokenize{pages/segment::doc}}
Segment a .ccf file using Bayesian blocks

Required parameters:
\begin{itemize}
\item {} 
-i, \textendash{}input INPUT: Input .ccf file

\item {} 
output: Output file (BED format)

\end{itemize}

Optional parameters:
\begin{itemize}
\item {} 
\textendash{}prior PRIOR: Explicit prior on the number of blocks (\sphinxstyleemphasis{not recommended for general use})

\item {} 
\textendash{}p0 P0: Empirical prior based on a specified false-positive rate; must be between 0 and 1 (default: 0.05)

\item {} 
\textendash{}method \{OP,PELT\}: Segment using the optimal partitioning (OP) or pruned exact linear time (PELT) algorithm (default: PELT)

\end{itemize}


\chapter{Command: call}
\label{\detokenize{pages/call:command-call}}\label{\detokenize{pages/call::doc}}
Call peaks in a .ccf file

Required parameters:
\begin{itemize}
\item {} 
-i, \textendash{}input INPUT: input .ccf file

\item {} 
output: output bed file

\item {} 
Either:
\begin{itemize}
\item {} 
-p, \textendash{}pValueCutoff PVALUECUTOFF: p-value cutoff (NOTE: This is a straight cutoff and will not take into account multiple hypothesis correction!), OR

\item {} 
-a, \textendash{}alpha ALPHA: alpha for multiple hypothesis correction (must be between 0 and 1) AND

\item {} 
\textendash{}correction CORRECTION: if alpha provided, need to specificity method of multiple hypothesis correction. See \sphinxhref{https://www.statsmodels.org/stable/generated/statsmodels.stats.multitest.multipletests.html}{statsmodels.stats.multitest} for a complete list of choices (default: bonferroni)

\end{itemize}

\item {} 
-bg, \textendash{}background BACKGROUND: Background .ccf file

\end{itemize}

Optional parameters:
\begin{itemize}
\item {} 
-r, \textendash{}regions REGIONS: Regions over which to normalize event counts; should be supplied as a BED file. If not provided, the input file will be segmented using Bayesian blocks. (all options from blockify segment are available)

\item {} 
\textendash{}intermediate INTERMEDIATE: Intermediate file to write verbose output (CSV format)

\item {} 
-d, \textendash{}distance DISTANCE: Merge features closer than this distance (bp)

\item {} 
\textendash{}min MIN: Report peaks larger than this cutoff (bp)

\item {} 
\textendash{}max MAX: Report peaks smaller than this cutoff (bp)

\item {} 
-t, \textendash{}tight: Shrink peak boundaries to overlap data points

\item {} 
-c, \textendash{}pseudocount PSEUDOCOUNT: Pseudocount for background regions (default: 1)

\end{itemize}


\chapter{Command: normalize}
\label{\detokenize{pages/normalize:command-normalize}}\label{\detokenize{pages/normalize::doc}}
Calculate normalized rates of events in a .ccf file

Required parameters:
\begin{itemize}
\item {} 
-i, \textendash{}input INPUT: input .ccf file

\item {} 
-o, \textendash{}output OUTPUT: Output file (bedGraph format)

\end{itemize}

Optional parameters:
\begin{itemize}
\item {} 
-r, \textendash{}regions REGIONS: Regions over which to normalize event counts; should be supplied as a BED file. If not provided, the input file will be segmented using Bayesian blocks. (all options from blockify segment are available)

\item {} 
-k, \textendash{}libraryFactor LIBRARYFACTOR: Normalization factor for library size (default: 1000000)

\item {} 
-l, \textendash{}lengthFactor LENGTHFACTOR: Normalization factor for the length of regions; used to calculate scaled rates of events per interval (default: None)

\end{itemize}


\chapter{Command: downsample}
\label{\detokenize{pages/downsample:command-downsample}}\label{\detokenize{pages/downsample::doc}}
Downsample a .ccf file in proportion to the value column

Required parameters:
\begin{itemize}
\item {} 
-i INPUT, \textendash{}input INPUT: Input .ccf file

\item {} 
-o, \textendash{}output OUTPUT: Output file (CCF format)

\item {} 
-n, \textendash{}number NUMBER: Number of entries to downsample to (cannot exceed length of input file)

\end{itemize}

Optional parameters:
\begin{itemize}
\item {} 
-s SEED, \textendash{}seed SEED: Random seed

\item {} 
\textendash{}naive: Sample every row with equal likelihood

\end{itemize}


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}